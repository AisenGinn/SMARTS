<h2>Evaluation</h2>

<!--Taken from https://stackoverflow.com/questions/12431339/how-to-write-equations-in-html-->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>

<p>
    Evaluation of your submission will be performed exactly the same as outlined in this
    competition's starting kit. However, the scenarios that are used for evaluation will
    be different.
</p>

<p>
    Evaluation will run your agent in multiple scenarios to evaluate its performance.
    The type of scenarios that are used will depend on which track your agent has been
    submitted to.
</p>
<ul>
<li>
    Track 1 will consist of left-turn scenarios with no traffic.
</li>
<li>
    Track 2 will consist of left-turn scenarios with varying degrees and types of
    traffic.
</li>
</ul>

<p>
    During evaluation, multiple metrics will be logged that can then be
    displayed on the leaderboard alongside your submission.
</p>
<ul>
<li>Score: The average score your agent achieved</li>
<li>Reached Goal: The proportion of evaluation scenarios completed</li>
<li>
    Collision: The proportion of evaluation scenarios that ended because of a collision
</li>
<li>
    Off Road: The proportion of evaluation scenarios that ended because the agent went
    off road
</li>
<li>
    Off Route: The proportion of evaluation scenarios that ended because the agent went
    off route
</li>
<li>
    Wrong Way: The proportion of evaluation scenarios that ended because the agent went
    the wrong way
</li>
<li>
    Timed Out: The proportion of evaluation scenarios that ended because the agent timed
    out
</li>
<li>
    Speed Violation: The proportion of scenarios that the agent went greater than 10%
    over the speed limit.
</li>
<li>
    Episode Length: The average number of timesteps the agent lasted
</li>
</ul>

<p>
    Submissions on the leaderboard will be ranked according to the "Score" metric. For
    each evaluation scenario, a "score" will be calculated. "Score" is the average of
    the scores over all the evaluation scenarios for that track. The formula for "score"
    is shown below:
</p>

$$ {\text{score}=\big(\text{reached_goal == 1.0}\big)\times\big(\text{speed_violation} == 0.0\big)\times\frac{\text{EXPECTED_STEPS}}{\text{steps}}} $$

<p>
    The score for the evaluation scenario will be 0 if the agent fails to reach the goal
    (an agent fails to reach the goal if they collide, go off road, go off route, go the
    wrong way, or time out), or if they have gone more than 10% over the speed limit.
    Otherwise, the score will be inversely proportional to the number of steps the agent
    took to complete the evaluation scenario ("steps"). The score will be scaled by
    "EXPECTED_STEPS", which is the average number of steps it takes a SUMO controlled
    vehicle to complete that type of evaluation scenario.
</p>

<p>This "Score" is what will be used to determine the winners of the competition.</p>
