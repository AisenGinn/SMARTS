smarts:
  # Environment
  seed: 42
  name: SB3
  visdom: False # If True, enables Visdom display.
  sumo_gui: False # If True, enables sumo-gui display.
  img_meters: 50
  img_pixels: 112
  n_stack: 3 # Number of frames to stack as input to policy network
  action_space: Continuous # Either "Lane" or "Continuous"
  action_space_wrapper: Discrete # Either "Lane" or "Continuous" or "Discrete"
  
  # Training
  train_steps: 1e8 # Number of training steps.
  checkpoint_freq: 1e5 # Save a model every checkpoint_freq calls to env.step().
  eval_eps: 5 # Number of evaluation epsiodes.
  eval_freq: 1e5 # Evaluate the trained model every eval_freq steps and save the best model.

  # Policy
  alg: PPO
  # alg: DQN
  
  policy: naturecnn
  # policy: customnaturecnn

  # policy: l5kit
  # img=pixels=112; img_meters=64; rgb; stack=4; action_space=Continuous
  # img=pixels=112; img_meters=64; rgb; stack=4; action_space=Lane

  # policy: dreamer
  # img=pixels=64; img_meters=64; rgb; stack=4; action_space=Continuous
  # img=pixels=64; img_meters=64; rgb; stack=4; action_space=Lane

  # policy: r2plus1d_18
  # img=pixels=112; img_meters=64; rgb; stack=4; action_space=Continuous
  # img=pixels=112; img_meters=64; rgb; stack=4; action_space=Lane

  # policy: dqn_naturecnn
