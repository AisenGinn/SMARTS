{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sb3-example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install SUMO"
      ],
      "metadata": {
        "id": "8gsMrWT3u4WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup SUMO=1.10.0\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install -y libspatialindex-dev\n",
        "%pip install --upgrade pip wheel\n",
        "%pip install eclipse-sumo==1.10.0\n",
        "%env SUMO_HOME=/usr/local/lib/python3.7/dist-packages/sumo"
      ],
      "metadata": {
        "id": "ou2m2vdkt6gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install SMARTS"
      ],
      "metadata": {
        "id": "Ovtp6ZCSuz1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install SMARTS\n",
        "%cd ~\n",
        "!rm -rf /content/SMARTS\n",
        "!git clone https://github.com/huawei-noah/SMARTS /content/SMARTS\n",
        "!cd /content/SMARTS && git checkout 'stable-baselines-3' && git pull && pip install .[camera-obs]\n",
        "!echo -e \"import sys\\nsys.path.insert(0, '/content/SMARTS/')\" | python"
      ],
      "metadata": {
        "id": "8O_JXIJ0t8ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Stable Baselines3"
      ],
      "metadata": {
        "id": "SrqfhFxtvmN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "id": "h3NGSm58vldU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the scenarios"
      ],
      "metadata": {
        "id": "dGJgn7UZu76M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build scenarios\n",
        "!scl scenario build-all --clean /content/SMARTS/scenarios/loop"
      ],
      "metadata": {
        "id": "g2xr24JSuWd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the runtime"
      ],
      "metadata": {
        "id": "Sx__xXLNpC25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the environment"
      ],
      "metadata": {
        "id": "3v0xcpPfv6L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "\n",
        "from smarts.core import agent as smarts_agent\n",
        "from smarts.core import agent_interface as smarts_agent_interface\n",
        "from smarts.core import controllers as smarts_controllers\n",
        "from smarts.env import hiway_env as smarts_hiway_env\n",
        "import examples.stable_baselines3.env.rgb_image as smarts_rgb_image\n",
        "import examples.stable_baselines3.env.single_agent as smarts_single_agent\n",
        "import examples.stable_baselines3.env.adapter as adapter\n",
        "import examples.stable_baselines3.env.action as action\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from examples.stable_baselines3.argument_parser import default_argument_parser\n",
        "\n",
        "def main(scenarios, headless, seed, sim_name):\n",
        "\n",
        "    vehicle_interface = smarts_agent_interface.AgentInterface(\n",
        "        max_episode_steps=300,\n",
        "        rgb=smarts_agent_interface.RGB(\n",
        "            width=64,\n",
        "            height=64,\n",
        "            resolution=1,\n",
        "        ),\n",
        "        action=getattr(\n",
        "            smarts_controllers.ActionSpaceType,\n",
        "            \"Continuous\",\n",
        "        ),\n",
        "        done_criteria=smarts_agent_interface.DoneCriteria(\n",
        "            collision=True,\n",
        "            off_road=True,\n",
        "            off_route=False,\n",
        "            on_shoulder=False,\n",
        "            wrong_way=False,\n",
        "            not_moving=False,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    agent_specs = {\n",
        "        \"Agent-007\": smarts_agent.AgentSpec(\n",
        "            interface=vehicle_interface,\n",
        "            agent_builder=None,\n",
        "            reward_adapter=adapter.reward_adapter,\n",
        "            info_adapter=adapter.info_adapter,\n",
        "        )\n",
        "    }\n",
        "\n",
        "    env = smarts_hiway_env.HiWayEnv(\n",
        "        scenarios=scenarios,\n",
        "        agent_specs=agent_specs,\n",
        "        headless=headless,\n",
        "        visdom=False,\n",
        "        seed=seed,\n",
        "        sim_name=sim_name,\n",
        "    )\n",
        "\n",
        "    # Wrap env with ActionWrapper\n",
        "    env = action.Action(env=env)\n",
        "    # Wrap env with RGBImage wrapper to only get rgb images in observation\n",
        "    env = smarts_rgb_image.RGBImage(env=env, num_stack=1)\n",
        "    # Wrap env with SingleAgent wrapper to be Gym compliant\n",
        "    env = smarts_single_agent.SingleAgent(env=env)\n",
        "    check_env(env, warn=True)\n",
        "\n",
        "    # create the model\n",
        "    model = PPO(\"CnnPolicy\", env, verbose=1)\n",
        "\n",
        "    # evaluate at the beginning\n",
        "    before_mean_reward, before_std_reward = evaluate_policy(\n",
        "        model, env, n_eval_episodes=10, deterministic=True\n",
        "    )\n",
        "    model.learn(total_timesteps=500000)\n",
        "\n",
        "    # evaluate after training\n",
        "    mean_reward, std_reward = evaluate_policy(\n",
        "        model, env, n_eval_episodes=10, deterministic=True\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"before_mean_reward:{before_mean_reward:.2f} +/- {before_std_reward:.2f}\"\n",
        "    )\n",
        "    print(f\"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "DWsQgj0NvGNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the example"
      ],
      "metadata": {
        "id": "s3JVKDRdyANx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(\n",
        "    scenarios=[\"/content/SMARTS/scenarios/loop\"],\n",
        "    sim_name=\"SB3-PPO\",\n",
        "    headless=True,\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "-0MXABlGxiIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}