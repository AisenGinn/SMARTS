{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gsMrWT3u4WM"
      },
      "source": [
        "Install SMARTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd ~\n",
        "!rm -rf /content/SMARTS\n",
        "!git clone https://github.com/huawei-noah/SMARTS /content/SMARTS 2> /dev/null\n",
        "!cd /content/SMARTS && git checkout sb3-1 && cd /content/SMARTS/examples/rl/intersection && pip install .[camera-obs]\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/SMARTS/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O_JXIJ0t8ub"
      },
      "outputs": [],
      "source": [
        "# Install SMARTS\n",
        "# %cd ~\n",
        "# !rm -rf /content/SMARTS\n",
        "# !git clone https://github.com/huawei-noah/SMARTS /content/SMARTS\n",
        "# !cd /content/SMARTS && git checkout 'develop' && cd /content/SMARTS/examples/rl/intersection && pip install .[camera-obs]\n",
        "# !echo -e \"import sys\\nsys.path.insert(0, '/content/SMARTS/')\" | python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_env(config: Dict[str, Any], training: bool) -> gym.Env:\n",
        "    # Create environment\n",
        "    env = gym.make(\n",
        "        \"smarts.env:intersection-v0\",\n",
        "        headless=not config[\"head\"],  # If False, enables Envision display.\n",
        "        visdom=config[\"visdom\"],  # If True, enables Visdom display.\n",
        "        sumo_headless=not config[\"sumo_gui\"],  # If False, enables sumo-gui display.\n",
        "        img_meters=config[\"img_meters\"],\n",
        "        img_pixels=config[\"img_pixels\"],\n",
        "        action_space=config[\"action_space\"],\n",
        "    )\n",
        "\n",
        "    # Wrap env with action, reward, and observation wrapper\n",
        "    env = sb3_info.Info(env=env)\n",
        "    env = sb3_action.Action(env=env, space=config[\"action_wrapper\"])\n",
        "    env = sb3_reward.Reward(env=env)\n",
        "    env = getattr(sb3_observation, config[\"observation_wrapper\"])(env=env)\n",
        "\n",
        "    # Check custom environment\n",
        "    check_env(env)\n",
        "\n",
        "    # Wrap env with SB3 wrappers\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "    env = VecFrameStack(venv=env, n_stack=config[\"n_stack\"], channels_order=\"first\")\n",
        "    env = VecMonitor(\n",
        "        venv=env,\n",
        "        filename=str(config[\"logdir\"]),\n",
        "        info_keywords=(\"is_success\",),\n",
        "    )\n",
        "\n",
        "    return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v0xcpPfv6L3"
      },
      "source": [
        "Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWsQgj0NvGNt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "\n",
        "import gym\n",
        "import stable_baselines3 as sb3lib\n",
        "import tensorflow as tf\n",
        "import torch as th\n",
        "from ruamel.yaml import YAML\n",
        "from intersection import action as intersection_action\n",
        "from intersection import info as intersection_info\n",
        "from intersection import observation as intersection_observation\n",
        "from intersection import policy as intersection_policy\n",
        "from intersection import reward as intersection_reward\n",
        "from intersection import util as intersection_util\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecMonitor\n",
        "\n",
        "print(\"\\nTorch cuda is available: \", th.cuda.is_available(), \"\\n\")\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "yaml = YAML(typ=\"safe\")\n",
        "\n",
        "\n",
        "def main(args: argparse.Namespace):\n",
        "    # Load config file.\n",
        "    config_file = yaml.load(\n",
        "        (Path(__file__).absolute().parent / \"config.yaml\").read_text()\n",
        "    )\n",
        "\n",
        "    # Load env config.\n",
        "    config = config_file[\"smarts\"]\n",
        "\n",
        "    # Setup logdir.\n",
        "    time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "    logdir = Path(__file__).absolute().parents[0] / \"logs\" / time\n",
        "    logdir.mkdir(parents=True, exist_ok=True)\n",
        "    config[\"logdir\"] = logdir\n",
        "    print(\"\\nLogdir:\", logdir, \"\\n\")\n",
        "\n",
        "    # Make training and evaluation environments.\n",
        "    env = make_env(config=config, training=True)\n",
        "    eval_env = make_env(config=config, training=False)\n",
        "\n",
        "    # Run training or evaluation.\n",
        "    run(env=env, eval_env=eval_env, config=config)\n",
        "    env.close()\n",
        "\n",
        "\n",
        "def run(env: gym.Env, eval_env: gym.Env, config: Dict[str, Any]):\n",
        "\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=config[\"checkpoint_freq\"],\n",
        "        save_path=config[\"logdir\"] / \"checkpoint\",\n",
        "        name_prefix=config[\"alg\"],\n",
        "    )\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env=eval_env,\n",
        "        n_eval_episodes=config[\"eval_eps\"],\n",
        "        eval_freq=config[\"eval_freq\"],\n",
        "        log_path=config[\"logdir\"] / \"eval\",\n",
        "        best_model_save_path=config[\"logdir\"] / \"eval\",\n",
        "        deterministic=True,\n",
        "    )\n",
        "\n",
        "    print(\"\\nStart training from scratch.\\n\")\n",
        "    model = getattr(sb3lib, config[\"alg\"])(\n",
        "        env=env,\n",
        "        verbose=1,\n",
        "        tensorboard_log=config[\"logdir\"] / \"tensorboard\",\n",
        "        **(getattr(sb3_policy, config[\"policy\"])(config)),\n",
        "    )\n",
        "    sb3_util.print_model(model, env, config[\"alg\"])\n",
        "    model.learn(\n",
        "        total_timesteps=config[\"train_steps\"],\n",
        "        callback=[checkpoint_callback, eval_callback],\n",
        "    )\n",
        "\n",
        "    if config[\"mode\"] == \"train\":\n",
        "        save_dir = config[\"logdir\"] / \"train\"\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "        model.save(save_dir / (\"model_\" + time))\n",
        "        print(\"\\nSaved trained model.\\n\")\n",
        "\n",
        "    print(\"\\nEvaluate policy.\\n\")\n",
        "    mean_reward, std_reward = evaluate_policy(\n",
        "        model, eval_env, n_eval_episodes=config[\"eval_eps\"], deterministic=True\n",
        "    )\n",
        "    print(f\"Mean reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "    print(\"\\nFinished evaluating.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "main(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View logs in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/SMARTS/examples/rl/intersection/logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3JVKDRdyANx"
      },
      "source": [
        "Run the example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0MXABlGxiIC"
      },
      "outputs": [],
      "source": [
        "# allow offscreen render\n",
        "import os\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "\n",
        "main(\n",
        "    scenarios=[\"/content/SMARTS/scenarios/loop\"],\n",
        "    sim_name=\"SB3-PPO\",\n",
        "    headless=True,\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate a pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "\n",
        "import gym\n",
        "import stable_baselines3 as sb3lib\n",
        "import tensorflow as tf\n",
        "import torch as th\n",
        "from ruamel.yaml import YAML\n",
        "from sb3 import action as sb3_action\n",
        "from sb3 import info as sb3_info\n",
        "from sb3 import observation as sb3_observation\n",
        "from sb3 import policy as sb3_policy\n",
        "from sb3 import reward as sb3_reward\n",
        "from sb3 import util as sb3_util\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecMonitor\n",
        "\n",
        "print(\"\\nTorch cuda is available: \", th.cuda.is_available(), \"\\n\")\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "yaml = YAML(typ=\"safe\")\n",
        "\n",
        "\n",
        "def main(args: argparse.Namespace):\n",
        "    # Load config file.\n",
        "    config_file = yaml.load(\n",
        "        (Path(__file__).absolute().parent / \"config.yaml\").read_text()\n",
        "    )\n",
        "\n",
        "    # Load env config.\n",
        "    config = config_file[\"smarts\"]\n",
        "    config[\"head\"] = args.head\n",
        "    config[\"mode\"] = args.mode\n",
        "\n",
        "    # Setup logdir.\n",
        "    if not args.logdir:\n",
        "        time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "        logdir = Path(__file__).absolute().parents[0] / \"logs\" / time\n",
        "    else:\n",
        "        logdir = Path(args.logdir)\n",
        "    logdir.mkdir(parents=True, exist_ok=True)\n",
        "    config[\"logdir\"] = logdir\n",
        "    print(\"\\nLogdir:\", logdir, \"\\n\")\n",
        "\n",
        "    # Setup model.\n",
        "    if (config[\"mode\"] == \"train\" and args.model) or (config[\"mode\"] == \"evaluate\"):\n",
        "        # Begin training or evaluation from a pretrained model.\n",
        "        config[\"model\"] = args.model\n",
        "        print(\"\\nModel:\", config[\"model\"], \"\\n\")\n",
        "    elif config[\"mode\"] == \"train\" and not args.model:\n",
        "        # Begin training from scratch.\n",
        "        pass\n",
        "    else:\n",
        "        raise KeyError(f'Expected \\'train\\' or \\'evaluate\\', but got {config[\"mode\"]}.')\n",
        "\n",
        "    # Make training and evaluation environments.\n",
        "    env = make_env(config=config, training=True)\n",
        "    eval_env = make_env(config=config, training=False)\n",
        "\n",
        "    # Run training or evaluation.\n",
        "    run(env=env, eval_env=eval_env, config=config)\n",
        "    env.close()\n",
        "\n",
        "\n",
        "def make_env(config: Dict[str, Any], training: bool) -> gym.Env:\n",
        "    # Create environment\n",
        "    env = gym.make(\n",
        "        \"smarts.env:intersection-v0\",\n",
        "        headless=not config[\"head\"],  # If False, enables Envision display.\n",
        "        visdom=config[\"visdom\"],  # If True, enables Visdom display.\n",
        "        sumo_headless=not config[\"sumo_gui\"],  # If False, enables sumo-gui display.\n",
        "        img_meters=config[\"img_meters\"],\n",
        "        img_pixels=config[\"img_pixels\"],\n",
        "        action_space=config[\"action_space\"],\n",
        "    )\n",
        "\n",
        "    # Wrap env with action, reward, and observation wrapper\n",
        "    env = sb3_info.Info(env=env)\n",
        "    env = sb3_action.Action(env=env, space=config[\"action_wrapper\"])\n",
        "    env = sb3_reward.Reward(env=env)\n",
        "    env = getattr(sb3_observation, config[\"observation_wrapper\"])(env=env)\n",
        "\n",
        "    # Check custom environment\n",
        "    check_env(env)\n",
        "\n",
        "    # Wrap env with SB3 wrappers\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "    env = VecFrameStack(venv=env, n_stack=config[\"n_stack\"], channels_order=\"first\")\n",
        "    env = VecMonitor(\n",
        "        venv=env,\n",
        "        filename=str(config[\"logdir\"]),\n",
        "        info_keywords=(\"is_success\",),\n",
        "    )\n",
        "\n",
        "    return env\n",
        "\n",
        "\n",
        "def run(env: gym.Env, eval_env: gym.Env, config: Dict[str, Any]):\n",
        "\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=config[\"checkpoint_freq\"],\n",
        "        save_path=config[\"logdir\"] / \"checkpoint\",\n",
        "        name_prefix=config[\"alg\"],\n",
        "    )\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env=eval_env,\n",
        "        n_eval_episodes=config[\"eval_eps\"],\n",
        "        eval_freq=config[\"eval_freq\"],\n",
        "        log_path=config[\"logdir\"] / \"eval\",\n",
        "        best_model_save_path=config[\"logdir\"] / \"eval\",\n",
        "        deterministic=True,\n",
        "    )\n",
        "    # video_recorder_callback = sb3_callback.VideoRecorderCallback(\n",
        "    #     env=eval_env,\n",
        "    # )\n",
        "\n",
        "    if config[\"mode\"] == \"evaluate\":\n",
        "        print(\"\\nStart evaluation.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"]).load(\n",
        "            config[\"model\"], print_system_info=True\n",
        "        )\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "    elif config[\"mode\"] == \"train\" and config.get(\"model\", None):\n",
        "        print(\"\\nStart training from existing model.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"]).load(\n",
        "            config[\"model\"], print_system_info=True\n",
        "        )\n",
        "        model.set_env(env)\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "        model.learn(\n",
        "            total_timesteps=config[\"train_steps\"],\n",
        "            callback=[checkpoint_callback, eval_callback],\n",
        "        )\n",
        "    else:\n",
        "        print(\"\\nStart training from scratch.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"])(\n",
        "            env=env,\n",
        "            verbose=1,\n",
        "            tensorboard_log=config[\"logdir\"] / \"tensorboard\",\n",
        "            **(getattr(sb3_policy, config[\"policy\"])(config)),\n",
        "        )\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "        model.learn(\n",
        "            total_timesteps=config[\"train_steps\"],\n",
        "            callback=[checkpoint_callback, eval_callback],\n",
        "        )\n",
        "\n",
        "    if config[\"mode\"] == \"train\":\n",
        "        save_dir = config[\"logdir\"] / \"train\"\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "        model.save(save_dir / (\"model_\" + time))\n",
        "        print(\"\\nSaved trained model.\\n\")\n",
        "\n",
        "    print(\"\\nEvaluate policy.\\n\")\n",
        "    mean_reward, std_reward = evaluate_policy(\n",
        "        model, eval_env, n_eval_episodes=config[\"eval_eps\"], deterministic=True\n",
        "    )\n",
        "    print(f\"Mean reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "    print(\"\\nFinished evaluating.\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    program = Path(__file__).stem\n",
        "    parser = argparse.ArgumentParser(program)\n",
        "    parser.add_argument(\n",
        "        \"--mode\",\n",
        "        help=\"`train` or `evaluate`. Default is `train`.\",\n",
        "        type=str,\n",
        "        default=\"train\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--logdir\",\n",
        "        help=\"Directory path for saving logs. Required if `--mode=evaluate`, else optional.\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model\",\n",
        "        help=\"Directory path to saved RL model. Required if `--mode=evaluate`, else optional.\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--head\", help=\"Run the simulation with display.\", action=\"store_true\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.mode == \"evaluate\" and args.model is None:\n",
        "        raise Exception(\"When --mode=evaluate, --model option must be specified.\")\n",
        "\n",
        "    main(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sb3_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
