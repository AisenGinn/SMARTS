{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gsMrWT3u4WM"
      },
      "source": [
        "Install SUMO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ou2m2vdkt6gt"
      },
      "outputs": [],
      "source": [
        "# Setup SUMO=1.10.0\n",
        "!apt-get update --fix-missing\n",
        "!apt-get install -y libspatialindex-dev\n",
        "%pip install --upgrade pip wheel\n",
        "%pip install eclipse-sumo==1.10.0\n",
        "%env SUMO_HOME=/usr/local/lib/python3.7/dist-packages/sumo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ovtp6ZCSuz1a"
      },
      "source": [
        "Install SMARTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O_JXIJ0t8ub"
      },
      "outputs": [],
      "source": [
        "# Install SMARTS\n",
        "%cd ~\n",
        "!rm -rf /content/SMARTS\n",
        "!git clone https://github.com/huawei-noah/SMARTS /content/SMARTS\n",
        "!cd /content/SMARTS && git checkout 'develop' && git pull && pip install .[camera-obs]\n",
        "!echo -e \"import sys\\nsys.path.insert(0, '/content/SMARTS/')\" | python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrqfhFxtvmN5"
      },
      "source": [
        "Install Stable Baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3NGSm58vldU"
      },
      "outputs": [],
      "source": [
        "!pip install stable_baselines3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGJgn7UZu76M"
      },
      "source": [
        "Build the scenarios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2xr24JSuWd3"
      },
      "outputs": [],
      "source": [
        "# Build scenarios\n",
        "!scl scenario build-all --clean /content/SMARTS/scenarios/loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx__xXLNpC25"
      },
      "source": [
        "Restart the runtime to change dependency versions. (Ctrl+M .) Continue from here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDGS3RHwfOT8"
      },
      "outputs": [],
      "source": [
        "%env SUMO_HOME=/usr/local/lib/python3.7/dist-packages/sumo\n",
        "%cd /content/SMARTS/examples/sb3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v0xcpPfv6L3"
      },
      "source": [
        "Create the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWsQgj0NvGNt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import argparse\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict\n",
        "\n",
        "import gym\n",
        "import stable_baselines3 as sb3lib\n",
        "import tensorflow as tf\n",
        "import torch as th\n",
        "from ruamel.yaml import YAML\n",
        "from sb3 import action as sb3_action\n",
        "from sb3 import info as sb3_info\n",
        "from sb3 import observation as sb3_observation\n",
        "from sb3 import policy as sb3_policy\n",
        "from sb3 import reward as sb3_reward\n",
        "from sb3 import util as sb3_util\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack, VecMonitor\n",
        "\n",
        "print(\"\\nTorch cuda is available: \", th.cuda.is_available(), \"\\n\")\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "yaml = YAML(typ=\"safe\")\n",
        "\n",
        "\n",
        "def main(args: argparse.Namespace):\n",
        "    # Load config file.\n",
        "    config_file = yaml.load(\n",
        "        (Path(__file__).absolute().parent / \"config.yaml\").read_text()\n",
        "    )\n",
        "\n",
        "    # Load env config.\n",
        "    config = config_file[\"smarts\"]\n",
        "    config[\"head\"] = args.head\n",
        "    config[\"mode\"] = args.mode\n",
        "\n",
        "    # Setup logdir.\n",
        "    if not args.logdir:\n",
        "        time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "        logdir = Path(__file__).absolute().parents[0] / \"logs\" / time\n",
        "    else:\n",
        "        logdir = Path(args.logdir)\n",
        "    logdir.mkdir(parents=True, exist_ok=True)\n",
        "    config[\"logdir\"] = logdir\n",
        "    print(\"\\nLogdir:\", logdir, \"\\n\")\n",
        "\n",
        "    # Setup model.\n",
        "    if (config[\"mode\"] == \"train\" and args.model) or (config[\"mode\"] == \"evaluate\"):\n",
        "        # Begin training or evaluation from a pretrained model.\n",
        "        config[\"model\"] = args.model\n",
        "        print(\"\\nModel:\", config[\"model\"], \"\\n\")\n",
        "    elif config[\"mode\"] == \"train\" and not args.model:\n",
        "        # Begin training from scratch.\n",
        "        pass\n",
        "    else:\n",
        "        raise KeyError(f'Expected \\'train\\' or \\'evaluate\\', but got {config[\"mode\"]}.')\n",
        "\n",
        "    # Make training and evaluation environments.\n",
        "    env = make_env(config=config, training=True)\n",
        "    eval_env = make_env(config=config, training=False)\n",
        "\n",
        "    # Run training or evaluation.\n",
        "    run(env=env, eval_env=eval_env, config=config)\n",
        "    env.close()\n",
        "\n",
        "\n",
        "def make_env(config: Dict[str, Any], training: bool) -> gym.Env:\n",
        "    # Create environment\n",
        "    env = gym.make(\n",
        "        \"smarts.env:intersection-v0\",\n",
        "        headless=not config[\"head\"],  # If False, enables Envision display.\n",
        "        visdom=config[\"visdom\"],  # If True, enables Visdom display.\n",
        "        sumo_headless=not config[\"sumo_gui\"],  # If False, enables sumo-gui display.\n",
        "        img_meters=config[\"img_meters\"],\n",
        "        img_pixels=config[\"img_pixels\"],\n",
        "        action_space=config[\"action_space\"],\n",
        "    )\n",
        "\n",
        "    # Wrap env with action, reward, and observation wrapper\n",
        "    env = sb3_info.Info(env=env)\n",
        "    env = sb3_action.Action(env=env, space=config[\"action_wrapper\"])\n",
        "    env = sb3_reward.Reward(env=env)\n",
        "    env = getattr(sb3_observation, config[\"observation_wrapper\"])(env=env)\n",
        "\n",
        "    # Check custom environment\n",
        "    check_env(env)\n",
        "\n",
        "    # Wrap env with SB3 wrappers\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "    env = VecFrameStack(venv=env, n_stack=config[\"n_stack\"], channels_order=\"first\")\n",
        "    env = VecMonitor(\n",
        "        venv=env,\n",
        "        filename=str(config[\"logdir\"]),\n",
        "        info_keywords=(\"is_success\",),\n",
        "    )\n",
        "\n",
        "    # Record evaluation video\n",
        "    # if not training:\n",
        "    # env = VecVideoRecorder(\n",
        "    #     venv=env,\n",
        "    #     video_folder=str(config[\"logdir\"] / \"videos\"),\n",
        "    #     record_video_trigger=lambda x: x == 0,\n",
        "    #     video_length=config[\"video_length\"],\n",
        "    #     name_prefix=config[\"name\"]+\"-PPO\"\n",
        "    # )\n",
        "\n",
        "    return env\n",
        "\n",
        "\n",
        "def run(env: gym.Env, eval_env: gym.Env, config: Dict[str, Any]):\n",
        "\n",
        "    checkpoint_callback = CheckpointCallback(\n",
        "        save_freq=config[\"checkpoint_freq\"],\n",
        "        save_path=config[\"logdir\"] / \"checkpoint\",\n",
        "        name_prefix=config[\"alg\"],\n",
        "    )\n",
        "    eval_callback = EvalCallback(\n",
        "        eval_env=eval_env,\n",
        "        n_eval_episodes=config[\"eval_eps\"],\n",
        "        eval_freq=config[\"eval_freq\"],\n",
        "        log_path=config[\"logdir\"] / \"eval\",\n",
        "        best_model_save_path=config[\"logdir\"] / \"eval\",\n",
        "        deterministic=True,\n",
        "    )\n",
        "    # video_recorder_callback = sb3_callback.VideoRecorderCallback(\n",
        "    #     env=eval_env,\n",
        "    # )\n",
        "\n",
        "    if config[\"mode\"] == \"evaluate\":\n",
        "        print(\"\\nStart evaluation.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"]).load(\n",
        "            config[\"model\"], print_system_info=True\n",
        "        )\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "    elif config[\"mode\"] == \"train\" and config.get(\"model\", None):\n",
        "        print(\"\\nStart training from existing model.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"]).load(\n",
        "            config[\"model\"], print_system_info=True\n",
        "        )\n",
        "        model.set_env(env)\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "        model.learn(\n",
        "            total_timesteps=config[\"train_steps\"],\n",
        "            callback=[checkpoint_callback, eval_callback],\n",
        "        )\n",
        "    else:\n",
        "        print(\"\\nStart training from scratch.\\n\")\n",
        "        model = getattr(sb3lib, config[\"alg\"])(\n",
        "            env=env,\n",
        "            verbose=1,\n",
        "            tensorboard_log=config[\"logdir\"] / \"tensorboard\",\n",
        "            **(getattr(sb3_policy, config[\"policy\"])(config)),\n",
        "        )\n",
        "        sb3_util.print_model(model, env, config[\"alg\"])\n",
        "        model.learn(\n",
        "            total_timesteps=config[\"train_steps\"],\n",
        "            callback=[checkpoint_callback, eval_callback],\n",
        "        )\n",
        "\n",
        "    if config[\"mode\"] == \"train\":\n",
        "        save_dir = config[\"logdir\"] / \"train\"\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "        time = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "        model.save(save_dir / (\"model_\" + time))\n",
        "        print(\"\\nSaved trained model.\\n\")\n",
        "\n",
        "    print(\"\\nEvaluate policy.\\n\")\n",
        "    mean_reward, std_reward = evaluate_policy(\n",
        "        model, eval_env, n_eval_episodes=config[\"eval_eps\"], deterministic=True\n",
        "    )\n",
        "    print(f\"Mean reward:{mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "    print(\"\\nFinished evaluating.\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    program = Path(__file__).stem\n",
        "    parser = argparse.ArgumentParser(program)\n",
        "    parser.add_argument(\n",
        "        \"--mode\",\n",
        "        help=\"`train` or `evaluate`. Default is `train`.\",\n",
        "        type=str,\n",
        "        default=\"train\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--logdir\",\n",
        "        help=\"Directory path for saving logs. Required if `--mode=evaluate`, else optional.\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model\",\n",
        "        help=\"Directory path to saved RL model. Required if `--mode=evaluate`, else optional.\",\n",
        "        type=str,\n",
        "        default=None,\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--head\", help=\"Run the simulation with display.\", action=\"store_true\"\n",
        "    )\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.mode == \"evaluate\" and args.model is None:\n",
        "        raise Exception(\"When --mode=evaluate, --model option must be specified.\")\n",
        "\n",
        "    main(args)\n",
        "\n",
        "    # import torchvision.models as th_models\n",
        "    # import torch\n",
        "    # pip install prefetch_generator tqdm yacs\n",
        "\n",
        "    # modelut = th_models.video.r2plus1d_18(pretrained=pretrained, progress=True)\n",
        "    # modelut = th.hub.load('datvuthanh/hybridnets', 'hybridnets', pretrained=True)\n",
        "    # model = torch.hub.load('hustvl/yolop', 'yolop', pretrained=True)\n",
        "    # Print model summary\n",
        "    # print(\"\\n\\n\")\n",
        "    # network = sb3_util.Network(modelut)\n",
        "    # print(model)\n",
        "    # sb3_util.summary(model=model, depth=10, input_size=(1,3,256,256))\n",
        "    # print(\"\\n\\n\")\n",
        "\n",
        "    # import gym\n",
        "    # import Box2D\n",
        "    # env = gym.make('RoadRunner-v0')\n",
        "    # print(\"obs_space\",env.observation_space)\n",
        "    # print(\"action_space\",env.action_space)\n",
        "\n",
        "    # import gym\n",
        "    # import torch as th\n",
        "\n",
        "    # from stable_baselines3 import PPO\n",
        "\n",
        "    # # Custom actor (pi) and value function (vf) networks\n",
        "    # # of two layers of size 32 each with Relu activation function\n",
        "    # policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
        "    #                     net_arch=[dict(pi=[32, 32], vf=[32, 32])])\n",
        "    # # Create the agent\n",
        "    # model = PPO(\"MlpPolicy\", \"CartPole-v1\", policy_kwargs=policy_kwargs, verbose=1)\n",
        "    # # Retrieve the environment\n",
        "    # env = model.get_env()\n",
        "    # print(env.observation_space)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View logs in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3JVKDRdyANx"
      },
      "source": [
        "Run the example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0MXABlGxiIC"
      },
      "outputs": [],
      "source": [
        "# allow offscreen render\n",
        "import os\n",
        "os.environ[\"PYOPENGL_PLATFORM\"] = \"egl\"\n",
        "\n",
        "main(\n",
        "    scenarios=[\"/content/SMARTS/scenarios/loop\"],\n",
        "    sim_name=\"SB3-PPO\",\n",
        "    headless=True,\n",
        "    seed=42,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "sb3_example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
